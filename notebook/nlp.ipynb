{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/columbia2131/training-inference-code-xlm-roberta-base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sys \n",
    "import os \n",
    "import logzero \n",
    "import wandb \n",
    "import pickle \n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "sns.set()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Config():\n",
    "    # common\n",
    "    version = '003'\n",
    "    comment = 'test'\n",
    "    input_dir = '/home/user/work/input/we-are-all-alike-on-the-inside'\n",
    "    output_dir = f'/home/user/work/output/{version}' \n",
    "    seed = 42\n",
    "    target_col = None \n",
    "\n",
    "    # wandb\n",
    "    wandb_init = {\n",
    "        \"project\": \"debug\",\n",
    "        \"entity\": \"kuto5046\",\n",
    "        \"group\": f\"exp{version}\",\n",
    "        \"dir\": output_dir,\n",
    "        \"tags\": [],\n",
    "        # \"mode\": \"disabled\", \n",
    "    }\n",
    "\n",
    "    # cv \n",
    "    n_splits = 5\n",
    "    use_fold = [0]  # fold1つで終える場合[0], 全てのfoldを実行する場合[0,1,2,3,4]\n",
    "\n",
    "    # dataloader\n",
    "    loader_params = {\n",
    "        'batch_size': 32,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 4,\n",
    "        }\n",
    "\n",
    "    # model\n",
    "    n_epochs = 10\n",
    "    model_path = 'xlm-roberta-base'\n",
    "    max_len = 128\n",
    "    weight_decay = 1e-5\n",
    "    beta = (0.9, 0.98)\n",
    "    lr = 2e-5\n",
    "    num_warmup_steps_rate = 0.01\n",
    "    clip_grad_norm = None\n",
    "    gradient_accumulation_steps = 1  # 1なら累積しない\n",
    "\n",
    "c = Config()\n",
    "# c = HydraConfig.get_cnf(config_path='/home/user/work/configs/', config_name='config.yaml')\n",
    "os.makedirs(c.output_dir, exist_ok=True)\n",
    "logger = logzero.setup_logger(name='main', logfile=f'{c.output_dir}/result.log', level=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "c.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(c.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'{c.input_dir}/train.csv')\n",
    "test = pd.read_csv(f'{c.input_dir}/test.csv')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.base import get_categorical_col, get_numerical_col\n",
    "from src.features.encoder import pp_for_categorical_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.target_col = 'category'\n",
    "c.n_class = 3\n",
    "c.target_map = {'association': 0, 'disagreement': 1, 'unbiased': 2}\n",
    "c.target_map_rev = {0: 'association', 1: 'disagreement', 2: 'unbiased'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_categorical_col(whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_numerical_col(whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ast \n",
    "# def fix_s1s2(data):\n",
    "#     new_s1 = []\n",
    "#     new_s2 = []\n",
    "#     for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "#         if row[\"s1\"].startswith(\"[\"):\n",
    "#             try:\n",
    "#                 temp_s1 = \" \".join(ast.literal_eval(row[\"s1\"]))\n",
    "#             except SyntaxError:\n",
    "#                 temp_s1 = row[\"s1\"][1:-1]\n",
    "#         else:\n",
    "#             temp_s1 = row[\"s1\"]\n",
    "\n",
    "#         if row[\"s2\"].startswith(\"[\"):\n",
    "#             try:\n",
    "#                 temp_s2 = \" \".join(ast.literal_eval(row[\"s2\"]))\n",
    "#             except SyntaxError:\n",
    "#                 temp_s2 = row[\"s2\"][1:-1]\n",
    "#         else:\n",
    "#             temp_s2 = row[\"s2\"]\n",
    "\n",
    "#         new_s1.append(temp_s1)\n",
    "#         new_s2.append(temp_s2)\n",
    "#     data[\"s1\"] = new_s1\n",
    "#     data[\"s2\"] = new_s2\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole['s1'] = whole['s1'].map(\n",
    "    lambda x: x\\\n",
    "        .replace(\"['\", '')\\\n",
    "        .replace(\"']\", '')\\\n",
    "        .replace('[\"', '')\\\n",
    "        .replace('\"]', '')\\\n",
    "        .replace('[«', '«')\n",
    "        .replace('»]', '»')\\\n",
    "        .replace('[', '')\\\n",
    "        .replace(']', '')\\\n",
    "        .split(\"', '\")\n",
    ")\n",
    "\n",
    "\n",
    "whole['s1'] = whole['s1'].map(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = whole[~whole[c.target_col].isna()].reset_index(drop=True)\n",
    "test = whole[whole[c.target_col].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelを数値に変換\n",
    "train[c.target_col] = train[c.target_col].map(c.target_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, config: Config, phase: str='train'):\n",
    "        assert phase in ['train', 'valid', 'test']\n",
    "        self.config = config\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.model_path)\n",
    "        self.phase = phase\n",
    "        self.s1 = df['s1'].to_numpy()\n",
    "        self.s2 = df['s2'].to_numpy()\n",
    "        self.y = np.nan\n",
    "        if self.phase in ['train', 'valid']:\n",
    "            self.y = df[config.target_col].to_numpy()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.s1.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # GET TEXT AND WORD LABELS \n",
    "        inputs1 = self.tokenizer.encode_plus(\n",
    "            self.s1[idx],\n",
    "            self.s2[idx],\n",
    "            max_length=self.config.max_len, \n",
    "            padding='max_length',\n",
    "            truncation=True, \n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "        \n",
    "        x = {\n",
    "            'token1': torch.tensor(inputs1['input_ids'], dtype=torch.long),\n",
    "            'mask1': torch.tensor(inputs1['attention_mask'], dtype=torch.long),\n",
    "        }\n",
    "        return x, self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_path, n_class):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.backbone = AutoModel.from_pretrained(model_path)\n",
    "        self.ln = nn.LayerNorm(768)\n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.Linear(768, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, n_class) \n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        output = self.backbone(x['token1'], attention_mask=x['mask1'])[\"last_hidden_state\"][:, 0, :]\n",
    "        output = self.ln(output)\n",
    "        output = self.linear1(output)        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from torchmetrics import F1Score\n",
    "\n",
    "class SimpleLearner(pl.LightningModule):\n",
    "    def __init__(self, model, config):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = self.get_criterion(config)\n",
    "        self.optimizer = self.get_optimizer(config)\n",
    "        self.scheduler = self.get_scheduler(config)\n",
    "        self.metric = self.get_metric(config)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        output = self.model(x)\n",
    "        loss = self.criterion(output, y)\n",
    "        score = self.metric(output, y) \n",
    "\n",
    "        self.log(f'Loss/train', loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        self.log(f'Score/train', score, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        output = self.model(x)\n",
    "        loss = self.criterion(output, y)\n",
    "        score = self.metric(output, y) \n",
    "        \n",
    "        self.log(f'Loss/val', loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        self.log(f'Score/val', score, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return {\"optimizer\": self.optimizer, \"lr_scheduler\": self.scheduler, \"monitor\": \"Loss/val\"}\n",
    "\n",
    "\n",
    "    def get_metric(self, config):\n",
    "        return F1Score(average='micro')\n",
    "\n",
    "\n",
    "    def get_optimizer(self, config: dict):\n",
    "\n",
    "        param_optimizer = list(self.model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']  # このパラメータはweight decayしない\n",
    "        optimizer_grouped_parameters = [\n",
    "                {\n",
    "                    'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n",
    "                    'weight_decay': config.weight_decay\n",
    "                },\n",
    "                {\n",
    "                    'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n",
    "                    'weight_decay': 0.0\n",
    "                }\n",
    "            ]\n",
    "\n",
    "        optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr = config.lr,\n",
    "            betas = config.beta,\n",
    "            weight_decay = config.weight_decay,\n",
    "            )\n",
    "        return optimizer\n",
    "\n",
    "    def get_scheduler(self, config: dict):\n",
    "        num_train_optimization_steps = int(\n",
    "            config.len_loader * config.n_epochs // config.gradient_accumulation_steps\n",
    "        )\n",
    "        num_warmup_steps = int(num_train_optimization_steps * config.num_warmup_steps_rate)\n",
    "        \n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            num_training_steps=num_train_optimization_steps\n",
    "        )\n",
    "        return scheduler \n",
    "\n",
    "\n",
    "    def get_criterion(self, config: dict):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        return criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cv import get_kfold, get_stratifiedkfold, get_groupkfold\n",
    "cv = get_stratifiedkfold(train, c.target_col, n_splits=5)\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(i_fold):\n",
    "    callbacks = []\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=f'Loss/val',\n",
    "        mode='min',\n",
    "        dirpath=c.output_dir,\n",
    "        verbose=False,\n",
    "        filename=f'model_fold{i_fold}')\n",
    "    callbacks.append(checkpoint_callback)\n",
    "\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='Loss/val',\n",
    "        min_delta=0.00,\n",
    "        patience=20,\n",
    "        verbose=False,\n",
    "        mode='min')\n",
    "    callbacks.append(early_stop_callback)\n",
    "    return callbacks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "def calc_score(true, pred):\n",
    "    return f1_score(true, pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np(input):\n",
    "    return input.detach().cpu().numpy()\n",
    "\n",
    "def worker_init_fn(worker_id):                                                          \n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "\n",
    "def inference(model, loader, phase='test'):\n",
    "    model.eval()\n",
    "    pred = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x, y = batch\n",
    "            output = model(x)\n",
    "            pred.append(to_np(output))\n",
    "    return np.concatenate(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipeline(train, test, cv, config, target_col):\n",
    "    oofs = []\n",
    "    preds = []\n",
    "    for i, (idx_train, idx_valid) in enumerate(cv):\n",
    "\n",
    "        if i not in c.use_fold:\n",
    "            continue \n",
    "\n",
    "        logger.info(\"############\")\n",
    "        logger.info(f\"fold {i}\")\n",
    "        logger.info(\"############\")\n",
    "        wandb.init(**config.wandb_init, name=f'exp{config.version}-fold{i}')\n",
    "        \n",
    "        _train = train.loc[idx_train].reset_index(drop=True)\n",
    "        _valid = train.loc[idx_valid].reset_index(drop=True)\n",
    "\n",
    "        loaders = {}\n",
    "        loaders[\"train\"] = DataLoader(CustomDataset(_train, config, phase=\"train\"), **config.loader_params, worker_init_fn=worker_init_fn) \n",
    "        loaders[\"valid\"] = DataLoader(CustomDataset(_valid, config, phase=\"valid\"), **config.loader_params, worker_init_fn=worker_init_fn)\n",
    "        loaders[\"test\"] = DataLoader(CustomDataset(test, config, phase=\"test\"), **config.loader_params, worker_init_fn=worker_init_fn)\n",
    "\n",
    "        config.len_loader = len(loaders['train'])\n",
    "\n",
    "        model = CustomModel(c.model_path, c.n_class)\n",
    "        # model_name = model.__class__.__name__\n",
    "        callbacks = get_callbacks(i)\n",
    "        learner = SimpleLearner(model, config)\n",
    "        trainer = pl.Trainer(\n",
    "            logger=[WandbLogger()], \n",
    "            callbacks=callbacks,\n",
    "            max_epochs=config.n_epochs,\n",
    "            devices='auto',\n",
    "            accelerator='auto',\n",
    "            # fast_dev_run=True,\n",
    "            deterministic=True,\n",
    "            # precision=16,\n",
    "            amp_backend='apex',\n",
    "            )\n",
    "        print('start train')\n",
    "        trainer.fit(learner, train_dataloaders=loaders['train'], val_dataloaders=loaders['valid'])\n",
    "        \n",
    "        print('create oof')\n",
    "        pred = inference(model, loaders['valid'])\n",
    "        oof_df = pd.DataFrame(pred, index=idx_valid)\n",
    "        oofs.append(oof_df)\n",
    "\n",
    "        # evaluate\n",
    "        print('evaluate valid data')\n",
    "        score = calc_score(_valid[c.target_col], pred)\n",
    "        logger.info(f'fold-{i} score: {score}')\n",
    "        wandb.log({'CV': score})\n",
    "\n",
    "        # pred\n",
    "        print('inference test data')\n",
    "        pred_test = inference(model, loaders['test'])\n",
    "        np.save(f\"{c.output_dir}/pred_test_{i}\", pred_test)\n",
    "        preds.append(pred_test)\n",
    "\n",
    "        if i != c.use_fold[-1]:\n",
    "            wandb.finish()\n",
    "\n",
    "    # oofを保存\n",
    "    oof = np.array(pd.concat(oofs).sort_index())\n",
    "    np.save(f\"{c.output_dir}/oof\", oof)\n",
    "    return model, oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, oof = train_pipeline(train, test, cv, c, c.target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(len(cv)):\n",
    "    # TODO 存在していればに変更\n",
    "    pred = np.load(f'{c.output_dir}/pred_test_{i}.npy')\n",
    "    preds.append(pred)\n",
    "pred_test = np.mean(preds, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(f'{c.input_dir}/sample_submission.csv')\n",
    "sub[c.target_col] = pred_test\n",
    "sub.to_csv(f'{c.output_dir}/submission_exp{c.version}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
