{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/columbia2131/training-inference-code-xlm-roberta-base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sys \n",
    "import os \n",
    "import logzero \n",
    "import wandb \n",
    "import pickle \n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "sns.set()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Config():\n",
    "    # common\n",
    "    version = '013'\n",
    "    comment = 'roberta-base'\n",
    "    input_dir = '/home/user/work/input/we-are-all-alike-on-the-inside'\n",
    "    output_dir = f'/home/user/work/output/{version}' \n",
    "    seed = 42\n",
    "    debug = False \n",
    "    target_col = None \n",
    "\n",
    "    # wandb\n",
    "    wandb_init = {\n",
    "        \"project\": \"debug\",\n",
    "        \"entity\": \"kuto5046\",\n",
    "        \"group\": f\"exp{version}\",\n",
    "        \"dir\": output_dir,\n",
    "        \"tags\": [],\n",
    "        \"resume\": True,\n",
    "        # \"mode\": \"disabled\", \n",
    "    }\n",
    "\n",
    "    # cv \n",
    "    n_splits = 5\n",
    "    use_fold = [0]  # fold1つで終える場合[0], 全てのfoldを実行する場合[0,1,2,3,4]\n",
    "\n",
    "    # dataloader\n",
    "    loader_params = {\n",
    "        \"train\": {'batch_size': 32, 'shuffle': True, 'num_workers': 4},\n",
    "        \"valid\": {'batch_size': 32, 'shuffle': False, 'num_workers': 4},\n",
    "        \"test\": {'batch_size': 32, 'shuffle': False, 'num_workers': 4} \n",
    "        }\n",
    "\n",
    "    # model\n",
    "    # res\n",
    "    resume_checkpoint_path = f\"{output_dir}/model_fold0_epoch=6.ckpt\"  # resume用\n",
    "    # pretrained_model_path = f\"{output_dir}/model_fold0_epoch=0.ckpt\"  # 予測のみ用 \n",
    "    n_epochs = 5\n",
    "    model_name = 'xlm-roberta-base'\n",
    "    max_len = 128\n",
    "    weight_decay = 1e-3\n",
    "    beta = (0.9, 0.98)\n",
    "    lr = 3e-5\n",
    "    num_warmup_steps_rate = 0\n",
    "    gradient_accumulation_steps = 1  # 1なら累積しない\n",
    "\n",
    "c = Config()\n",
    "DEBUG = c.debug \n",
    "# c = HydraConfig.get_cnf(config_path='/home/user/work/configs/', config_name='config.yaml')\n",
    "os.makedirs(c.output_dir, exist_ok=True)\n",
    "logger = logzero.setup_logger(name='main', logfile=f'{c.output_dir}/result.log', level=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "c.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "seed_everything(c.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((209573, 9), (139716, 8))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(f'{c.input_dir}/train.csv')\n",
    "test = pd.read_csv(f'{c.input_dir}/test.csv')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>lang</th>\n",
       "      <th>lang_code</th>\n",
       "      <th>sim1</th>\n",
       "      <th>sim2</th>\n",
       "      <th>sim3</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12c14e636472ca96a4d2278e0551d386</td>\n",
       "      <td>Un caméraman regarde une performance.</td>\n",
       "      <td>Un caméraman filmant une performance musicale.</td>\n",
       "      <td>French</td>\n",
       "      <td>fr</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>association</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>952d00e2403b239e9c74270bc0a95221</td>\n",
       "      <td>['Dos mujeres miran al espacio.', 'Ii charwoma...</td>\n",
       "      <td>Dos mujeres buscan en algún evento distante.</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>es</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>association</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e10fc0fe22685baa17a93d63834f2773</td>\n",
       "      <td>There is a person in the snow.</td>\n",
       "      <td>A person playing sports in the snow is crouche...</td>\n",
       "      <td>English</td>\n",
       "      <td>en</td>\n",
       "      <td>0.597614</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>association</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b137d6a58a985c4fef34a59df5dd5b82</td>\n",
       "      <td>['Der Militär steht mit seiner Gitarre.', 'Der...</td>\n",
       "      <td>Ein Mann mit weißem Tanktop und Brille steuert...</td>\n",
       "      <td>German</td>\n",
       "      <td>de</td>\n",
       "      <td>0.094491</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cfb0eb8ff2d3f5dc191db41156e4acf1</td>\n",
       "      <td>[\"el pasajero de la moto de tierra está cruzan...</td>\n",
       "      <td>un ciclista de dirt bike cruza la roca.</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>es</td>\n",
       "      <td>0.612372</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unbiased</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  12c14e636472ca96a4d2278e0551d386   \n",
       "1  952d00e2403b239e9c74270bc0a95221   \n",
       "2  e10fc0fe22685baa17a93d63834f2773   \n",
       "3  b137d6a58a985c4fef34a59df5dd5b82   \n",
       "4  cfb0eb8ff2d3f5dc191db41156e4acf1   \n",
       "\n",
       "                                                  s1  \\\n",
       "0              Un caméraman regarde une performance.   \n",
       "1  ['Dos mujeres miran al espacio.', 'Ii charwoma...   \n",
       "2                     There is a person in the snow.   \n",
       "3  ['Der Militär steht mit seiner Gitarre.', 'Der...   \n",
       "4  [\"el pasajero de la moto de tierra está cruzan...   \n",
       "\n",
       "                                                  s2     lang lang_code  \\\n",
       "0     Un caméraman filmant une performance musicale.   French        fr   \n",
       "1       Dos mujeres buscan en algún evento distante.  Spanish        es   \n",
       "2  A person playing sports in the snow is crouche...  English        en   \n",
       "3  Ein Mann mit weißem Tanktop und Brille steuert...   German        de   \n",
       "4            un ciclista de dirt bike cruza la roca.  Spanish        es   \n",
       "\n",
       "       sim1  sim2  sim3      category  \n",
       "0  0.666667     0   0.0   association  \n",
       "1  0.288675     0   0.0   association  \n",
       "2  0.597614     0   0.0   association  \n",
       "3  0.094491     0   0.0  disagreement  \n",
       "4  0.612372     0   0.0      unbiased  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.base import get_categorical_col, get_numerical_col\n",
    "from src.features.encoder import pp_for_categorical_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.target_col = 'category'\n",
    "c.n_class = 3\n",
    "c.target_map = {'association': 0, 'disagreement': 1, 'unbiased': 2}\n",
    "c.target_map_rev = {0: 'association', 1: 'disagreement', 2: 'unbiased'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 's1', 's2', 'lang', 'lang_code', 'category']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_categorical_col(whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sim1', 'sim2', 'sim3']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_numerical_col(whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ast \n",
    "# def fix_s1s2(data):\n",
    "#     new_s1 = []\n",
    "#     new_s2 = []\n",
    "#     for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "#         if row[\"s1\"].startswith(\"[\"):\n",
    "#             try:\n",
    "#                 temp_s1 = \" \".join(ast.literal_eval(row[\"s1\"]))\n",
    "#             except SyntaxError:\n",
    "#                 temp_s1 = row[\"s1\"][1:-1]\n",
    "#         else:\n",
    "#             temp_s1 = row[\"s1\"]\n",
    "\n",
    "#         if row[\"s2\"].startswith(\"[\"):\n",
    "#             try:\n",
    "#                 temp_s2 = \" \".join(ast.literal_eval(row[\"s2\"]))\n",
    "#             except SyntaxError:\n",
    "#                 temp_s2 = row[\"s2\"][1:-1]\n",
    "#         else:\n",
    "#             temp_s2 = row[\"s2\"]\n",
    "\n",
    "#         new_s1.append(temp_s1)\n",
    "#         new_s2.append(temp_s2)\n",
    "#     data[\"s1\"] = new_s1\n",
    "#     data[\"s2\"] = new_s2\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole = fix_s1s2(whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole['s1'] = whole['s1'].map(\n",
    "    lambda x: x\\\n",
    "        .replace(\"['\", '')\\\n",
    "        .replace(\"']\", '')\\\n",
    "        .replace('[\"', '')\\\n",
    "        .replace('\"]', '')\\\n",
    "        .replace('[«', '«')\n",
    "        .replace('»]', '»')\\\n",
    "        .replace('[', '')\\\n",
    "        .replace(']', '')\\\n",
    "        .split(\"', '\")\n",
    ")\n",
    "\n",
    "\n",
    "whole['s1'] = whole['s1'].map(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = whole[~whole[c.target_col].isna()].reset_index(drop=True)\n",
    "test = whole[whole[c.target_col].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelを数値に変換\n",
    "train[c.target_col] = train[c.target_col].map(c.target_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 10:27:01.325463: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-12 10:27:01.442095: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-12 10:27:01.794904: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.8/site-packages/torch/lib:/opt/conda/lib/python3.8/site-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-12 10:27:01.794958: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.8/site-packages/torch/lib:/opt/conda/lib/python3.8/site-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-12 10:27:01.794964: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, config: Config, phase: str='train'):\n",
    "        assert phase in ['train', 'valid', 'test']\n",
    "        self.config = config\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "        self.phase = phase\n",
    "        self.s1 = df['s1'].to_numpy()\n",
    "        self.s2 = df['s2'].to_numpy()\n",
    "        self.y = np.full(len(df), np.nan)\n",
    "        if self.phase in ['train', 'valid']:\n",
    "            self.y = df[config.target_col].to_numpy()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.s1.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # GET TEXT AND WORD LABELS \n",
    "        inputs1 = self.tokenizer.encode_plus(\n",
    "            self.s1[idx],\n",
    "            self.s2[idx],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.config.max_len, \n",
    "            padding='max_length',\n",
    "            truncation=True, \n",
    "            # return_attention_mask=True,\n",
    "        )\n",
    "        \n",
    "        x = {\n",
    "            'token1': torch.tensor(inputs1['input_ids'], dtype=torch.long),\n",
    "            'mask1': torch.tensor(inputs1['attention_mask'], dtype=torch.long),\n",
    "        }\n",
    "        return x, self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from torchmetrics import F1Score\n",
    "\n",
    "class CustomModel(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = AutoModel.from_pretrained(config.model_name)\n",
    "        ndim = 768\n",
    "        self.ln = nn.LayerNorm(ndim)\n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.Linear(ndim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, config.n_class) \n",
    "        )\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "        self.criterion = self.get_criterion(config)\n",
    "        self.optimizer = self.get_optimizer(config)\n",
    "        self.scheduler = self.get_scheduler(config)\n",
    "        self.metric = self.get_metric(config)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        self.dropout4 = nn.Dropout(0.4)\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.backbone(x['token1'], attention_mask=x['mask1'])[\"last_hidden_state\"][:, 0, :]\n",
    "        output = self.ln(output)\n",
    "        logits1 = self.linear1(self.dropout1(output))   \n",
    "        logits2 = self.linear1(self.dropout2(output))   \n",
    "        logits3 = self.linear1(self.dropout3(output))   \n",
    "        logits4 = self.linear1(self.dropout4(output))   \n",
    "        logits5 = self.linear1(self.dropout5(output))   \n",
    "        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n",
    "        logits = torch.softmax(logits, dim=-1)\n",
    "        return output\n",
    "    \n",
    "\n",
    "    def _calculate_loss(self, batch, mode=\"train\"):\n",
    "        x, y = batch\n",
    "        output = self(x)\n",
    "        loss = self.criterion(output, y)\n",
    "        score = self.metric(output, y) \n",
    "\n",
    "        self.log(f'Loss/{mode}', loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        self.log(f'Score/{mode}', score, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        return loss \n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._calculate_loss(batch, mode=\"train\")\n",
    "    \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._calculate_loss(batch, mode=\"valid\")\n",
    "\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        return self(x)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return {\"optimizer\": self.optimizer, \"lr_scheduler\": self.scheduler, \"monitor\": \"Loss/valid\"}\n",
    "\n",
    "\n",
    "    def get_metric(self, config):\n",
    "        return F1Score(average='micro')\n",
    "\n",
    "\n",
    "    def get_optimizer(self, config: dict):\n",
    "\n",
    "        param_optimizer = list(self.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']  # このパラメータはweight decayしない\n",
    "        optimizer_grouped_parameters = [\n",
    "                {\n",
    "                    'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n",
    "                    'weight_decay': config.weight_decay\n",
    "                },\n",
    "                {\n",
    "                    'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n",
    "                    'weight_decay': 0.0\n",
    "                }\n",
    "            ]\n",
    "\n",
    "        optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr = config.lr,\n",
    "            betas = config.beta,\n",
    "            weight_decay = config.weight_decay,\n",
    "            )\n",
    "        return optimizer\n",
    "\n",
    "    def get_scheduler(self, config: dict):\n",
    "        num_train_optimization_steps = int(\n",
    "            config.len_loader * config.n_epochs // config.gradient_accumulation_steps\n",
    "        )\n",
    "        num_warmup_steps = int(num_train_optimization_steps * config.num_warmup_steps_rate)\n",
    "        \n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            num_training_steps=num_train_optimization_steps\n",
    "        )\n",
    "        return scheduler \n",
    "\n",
    "\n",
    "    def get_criterion(self, config: dict):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        return criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([     0,      1,      2, ..., 209567, 209571, 209572]),\n",
       "  array([     7,     11,     13, ..., 209568, 209569, 209570])),\n",
       " (array([     0,      1,      2, ..., 209569, 209570, 209572]),\n",
       "  array([     9,     17,     22, ..., 209561, 209565, 209571])),\n",
       " (array([     0,      1,      3, ..., 209570, 209571, 209572]),\n",
       "  array([     2,      5,      8, ..., 209545, 209564, 209566])),\n",
       " (array([     0,      1,      2, ..., 209570, 209571, 209572]),\n",
       "  array([     3,      4,      6, ..., 209558, 209563, 209567])),\n",
       " (array([     2,      3,      4, ..., 209569, 209570, 209571]),\n",
       "  array([     0,      1,     12, ..., 209549, 209562, 209572]))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.cv import get_kfold, get_stratifiedkfold, get_groupkfold\n",
    "cv = get_stratifiedkfold(train, c.target_col, n_splits=5)\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "def calc_score(true, pred):\n",
    "    return f1_score(true, pred.argmax(axis=1), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_device_to_dict(_dict, device):\n",
    "    for k, v in _dict.items():\n",
    "        _dict[k] = v.to(device)\n",
    "    return _dict \n",
    "    \n",
    "def to_np(input):\n",
    "    return input.detach().cpu().numpy()\n",
    "\n",
    "def worker_init_fn(worker_id):                                                          \n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "\n",
    "# def inference(model, loader, device):\n",
    "#     model.eval()\n",
    "#     model.to(device)\n",
    "#     pred = []\n",
    "#     with torch.no_grad():\n",
    "#         # https://github.com/tqdm/tqdm/issues/746\n",
    "#         for batch in tqdm(loader, total=len(loader)):\n",
    "#             with torch.autocast(device_type=device.type):\n",
    "#                 x, y = batch\n",
    "#                 x = apply_device_to_dict(x, device)\n",
    "#                 output = model(x)\n",
    "#                 pred.append(to_np(output))\n",
    "#     return np.concatenate(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipeline(train, test, cv, config, target_col):\n",
    "    for i, (idx_train, idx_valid) in enumerate(cv):\n",
    "        if i not in c.use_fold:\n",
    "            continue \n",
    "\n",
    "        wandb.init(**config.wandb_init, name=f'exp{config.version}-fold{i}', config=config)\n",
    "\n",
    "        _train = train.loc[idx_train].reset_index(drop=True)\n",
    "        _valid = train.loc[idx_valid].reset_index(drop=True)\n",
    "\n",
    "        loaders = {}\n",
    "        loaders[\"train\"] = DataLoader(CustomDataset(_train, config, phase=\"train\"), **config.loader_params['train'], worker_init_fn=worker_init_fn) \n",
    "        loaders[\"valid\"] = DataLoader(CustomDataset(_valid, config, phase=\"valid\"), **config.loader_params['valid'], worker_init_fn=worker_init_fn)\n",
    "        loaders[\"test\"] = DataLoader(CustomDataset(test, config, phase=\"test\"), **config.loader_params['test'], worker_init_fn=worker_init_fn)\n",
    "        c.len_loader = len(loaders['train'])\n",
    "\n",
    "\n",
    "\n",
    "        # callback \n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            monitor=f'Score/valid',\n",
    "            mode='max',\n",
    "            dirpath=c.output_dir,\n",
    "            filename=f'model_fold{i}_' + '{epoch}'  # pl内部のepochを読む\n",
    "            )  \n",
    "\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=f'Score/valid',\n",
    "            mode='max'\n",
    "            )\n",
    "\n",
    "        trainer = pl.Trainer(\n",
    "            logger=[WandbLogger()], \n",
    "            callbacks=[checkpoint_callback, early_stop_callback],\n",
    "            max_epochs=c.n_epochs,\n",
    "            devices='auto',\n",
    "            accelerator='auto',\n",
    "            fast_dev_run=DEBUG,\n",
    "            deterministic=True,\n",
    "            precision=16,\n",
    "            )\n",
    "\n",
    "        print('start train')\n",
    "        model = CustomModel(c)\n",
    "        trainer.fit(model, train_dataloaders=loaders['train'], val_dataloaders=loaders['valid'], ckpt_path=c.resume_checkpoint_path) # resumeする場合ここにcheckpointを渡す\n",
    "\n",
    "\n",
    "        print('create oof')\n",
    "        if not DEBUG:\n",
    "            # best_checkpoint_path = f\"{config.output_dir}/model_fold0_epoch=0.ckpt\" # \n",
    "            best_checkpoint_path = checkpoint_callback.best_model_path\n",
    "            logger.info(f'load best model {best_checkpoint_path}')\n",
    "            model = model.load_from_checkpoint(checkpoint_path=best_checkpoint_path, config=config)\n",
    "            config.best_checkpoint_path = best_checkpoint_path\n",
    "\n",
    "        preds_valid = trainer.predict(model, loaders['valid'])\n",
    "        pred_valid = to_np(torch.cat(preds_valid))\n",
    "        oof = pd.DataFrame(pred_valid, index=idx_valid)\n",
    "        oof.to_csv(f\"{c.output_dir}/oof_{i}.csv\", index=True) # もとの並びでconcatするときにindexが必要\n",
    "\n",
    "        # evaluate\n",
    "        print('evaluate valid data')\n",
    "        score = calc_score(_valid[c.target_col], pred_valid)\n",
    "        logger.info(f'fold-{i} score: {score}')\n",
    "        wandb.log({'CV': score})\n",
    "\n",
    "        # pred\n",
    "        print('inference test data')\n",
    "        preds_test = trainer.predict(model, loaders['test'])\n",
    "        pred_test = to_np(torch.cat(preds_test))\n",
    "        np.save(f\"{c.output_dir}/pred_test_{i}\", pred_test)\n",
    "\n",
    "        # if i != c.use_fold[-1]:\n",
    "        #     wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkuto5046\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user/work/output/012/wandb/run-20221012_102703-35m1l6sj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kuto5046/debug/runs/35m1l6sj\" target=\"_blank\">exp012-fold0</a></strong> to <a href=\"https://wandb.ai/kuto5046/debug\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:352: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /home/user/work/output/012 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "Restoring states from the checkpoint path at /home/user/work/output/012/model_fold0_epoch=6.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type             | Params\n",
      "------------------------------------------------\n",
      "0  | backbone  | XLMRobertaModel  | 278 M \n",
      "1  | ln        | LayerNorm        | 1.5 K \n",
      "2  | linear1   | Sequential       | 197 K \n",
      "3  | dropout   | Dropout          | 0     \n",
      "4  | criterion | CrossEntropyLoss | 0     \n",
      "5  | metric    | F1Score          | 0     \n",
      "6  | dropout1  | Dropout          | 0     \n",
      "7  | dropout2  | Dropout          | 0     \n",
      "8  | dropout3  | Dropout          | 0     \n",
      "9  | dropout4  | Dropout          | 0     \n",
      "10 | dropout5  | Dropout          | 0     \n",
      "------------------------------------------------\n",
      "278 M     Trainable params\n",
      "0         Non-trainable params\n",
      "278 M     Total params\n",
      "556.486   Total estimated model params size (MB)\n",
      "Restored all states from the checkpoint file at /home/user/work/output/012/model_fold0_epoch=6.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa2b94c9fcf4e83b16eb5ea58623ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a22ec993aaa4dddac6dc400ec8f5bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 5240it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37da5707f78c49fd849da5182c1b5009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475f0a83d470409399cdba9100ae254c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97abf3d012f49c3a254b490de21b8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "[I 221012 11:02:41 3718308697:52] load best model /home/user/work/output/012/model_fold0_epoch=7.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create oof\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c977c010e2234967bc414adc69bef08f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 5240it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 221012 11:03:36 3718308697:64] fold-0 score: 0.7747584396993916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate valid data\n",
      "inference test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9cd2f36baa045c1af796bd99f6c2823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 5240it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_pipeline(train, test, cv, c, c.target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(len(cv)):\n",
    "    if i not in c.use_fold:\n",
    "        continue \n",
    "    # TODO 存在していればに変更\n",
    "    pred = np.load(f'{c.output_dir}/pred_test_{i}.npy')\n",
    "    preds.append(pred)\n",
    "pred_test = np.mean(preds, axis=0).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/opt/conda/lib/python3.8/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train[c.target_col], label='target')\n",
    "sns.distplot(pred_test, label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(f'{c.input_dir}/sample_submission.csv')\n",
    "sub[c.target_col] = pred_test\n",
    "sub.to_csv(f'{c.output_dir}/submission_exp{c.version}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
