{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sys \n",
    "import os \n",
    "import logzero \n",
    "import wandb \n",
    "import pickle \n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "sns.set()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN_COLAB:False, IN_KAGGLE:False, LOCAL:True\n"
     ]
    }
   ],
   "source": [
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "IN_KAGGLE = 'kaggle_web_client' in sys.modules\n",
    "LOCAL = not (IN_KAGGLE or IN_COLAB)\n",
    "print(f'IN_COLAB:{IN_COLAB}, IN_KAGGLE:{IN_KAGGLE}, LOCAL:{LOCAL}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_KAGGLE or IN_COLAB:\n",
    "    %env CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
    "    !pip install -q \\\n",
    "        pytorch-lightning==1.7.6 \\\n",
    "        logzero \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_KAGGLE:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    wandb_api_key = UserSecretsClient().get_secret(\"wandb_api\")\n",
    "    wandb.login(key=wandb_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Config():\n",
    "    # common\n",
    "    version = '014'\n",
    "    comment = 'roberta-base'\n",
    "    input_dir = '/home/user/work/input/we-are-all-alike-on-the-inside'\n",
    "    output_dir = f'/home/user/work/output/{version}' \n",
    "    seed = 42\n",
    "    debug = False\n",
    "    target_col = None \n",
    "\n",
    "    # wandb\n",
    "    wandb_init = {\n",
    "        \"project\": \"debug\",\n",
    "        \"entity\": \"kuto5046\",\n",
    "        \"group\": f\"exp{version}\",\n",
    "        \"dir\": output_dir,\n",
    "        \"tags\": [],\n",
    "        # \"resume\": True,\n",
    "        # \"mode\": \"disabled\", \n",
    "    }\n",
    "\n",
    "    # cv \n",
    "    n_splits = 5\n",
    "    use_fold = [0]  # fold1つで終える場合[0], 全てのfoldを実行する場合[0,1,2,3,4]\n",
    "\n",
    "    # dataloader\n",
    "    loader_params = {\n",
    "        \"train\": {'batch_size': 32, 'shuffle': True, 'num_workers': 4},\n",
    "        \"valid\": {'batch_size': 32, 'shuffle': False, 'num_workers': 4},\n",
    "        \"test\": {'batch_size': 32, 'shuffle': False, 'num_workers': 4} \n",
    "        }\n",
    "\n",
    "    # model\n",
    "    resume_checkpoint_path = None #f\"{output_dir}/model_fold0_epoch=6.ckpt\"  # resume用\n",
    "    # pretrained_model_path = f\"{output_dir}/model_fold0_epoch=0.ckpt\"  # 予測のみ用 \n",
    "    n_epochs = 5\n",
    "    model_name = 'xlm-roberta-base'\n",
    "    ndim = 768\n",
    "    max_len = 128\n",
    "    weight_decay = 1e-3\n",
    "    beta = (0.9, 0.98)\n",
    "    lr = 3e-5\n",
    "    num_warmup_steps_rate = 0\n",
    "    gradient_accumulation_steps = 1  # 1なら累積しない\n",
    "\n",
    "    # model_config_params = {\n",
    "    #     \"output_hidden_states\": True,\n",
    "    #     \"hidden_dropout_prob\": 0.1,\n",
    "    #     \"layer_norm_eps\": 1e-7,\n",
    "    #     \"add_pooling_layer\": True,\n",
    "    # }\n",
    "\n",
    "\n",
    "c = Config()\n",
    "DEBUG = c.debug \n",
    "if DEBUG:\n",
    "    c.wandb_init[\"mode\"] = 'disabled' \n",
    "\n",
    "\n",
    "# c = HydraConfig.get_cnf(config_path='/home/user/work/configs/', config_name='config.yaml')\n",
    "os.makedirs(c.output_dir, exist_ok=True)\n",
    "logger = logzero.setup_logger(name='main', logfile=f'{c.output_dir}/result.log', level=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "c.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "seed_everything(c.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((209573, 9), (139716, 8))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(f'{c.input_dir}/train.csv')\n",
    "test = pd.read_csv(f'{c.input_dir}/test.csv')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>lang</th>\n",
       "      <th>lang_code</th>\n",
       "      <th>sim1</th>\n",
       "      <th>sim2</th>\n",
       "      <th>sim3</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12c14e636472ca96a4d2278e0551d386</td>\n",
       "      <td>Un caméraman regarde une performance.</td>\n",
       "      <td>Un caméraman filmant une performance musicale.</td>\n",
       "      <td>French</td>\n",
       "      <td>fr</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>association</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>952d00e2403b239e9c74270bc0a95221</td>\n",
       "      <td>['Dos mujeres miran al espacio.', 'Ii charwoma...</td>\n",
       "      <td>Dos mujeres buscan en algún evento distante.</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>es</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>association</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e10fc0fe22685baa17a93d63834f2773</td>\n",
       "      <td>There is a person in the snow.</td>\n",
       "      <td>A person playing sports in the snow is crouche...</td>\n",
       "      <td>English</td>\n",
       "      <td>en</td>\n",
       "      <td>0.597614</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>association</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b137d6a58a985c4fef34a59df5dd5b82</td>\n",
       "      <td>['Der Militär steht mit seiner Gitarre.', 'Der...</td>\n",
       "      <td>Ein Mann mit weißem Tanktop und Brille steuert...</td>\n",
       "      <td>German</td>\n",
       "      <td>de</td>\n",
       "      <td>0.094491</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cfb0eb8ff2d3f5dc191db41156e4acf1</td>\n",
       "      <td>[\"el pasajero de la moto de tierra está cruzan...</td>\n",
       "      <td>un ciclista de dirt bike cruza la roca.</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>es</td>\n",
       "      <td>0.612372</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unbiased</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  12c14e636472ca96a4d2278e0551d386   \n",
       "1  952d00e2403b239e9c74270bc0a95221   \n",
       "2  e10fc0fe22685baa17a93d63834f2773   \n",
       "3  b137d6a58a985c4fef34a59df5dd5b82   \n",
       "4  cfb0eb8ff2d3f5dc191db41156e4acf1   \n",
       "\n",
       "                                                  s1  \\\n",
       "0              Un caméraman regarde une performance.   \n",
       "1  ['Dos mujeres miran al espacio.', 'Ii charwoma...   \n",
       "2                     There is a person in the snow.   \n",
       "3  ['Der Militär steht mit seiner Gitarre.', 'Der...   \n",
       "4  [\"el pasajero de la moto de tierra está cruzan...   \n",
       "\n",
       "                                                  s2     lang lang_code  \\\n",
       "0     Un caméraman filmant une performance musicale.   French        fr   \n",
       "1       Dos mujeres buscan en algún evento distante.  Spanish        es   \n",
       "2  A person playing sports in the snow is crouche...  English        en   \n",
       "3  Ein Mann mit weißem Tanktop und Brille steuert...   German        de   \n",
       "4            un ciclista de dirt bike cruza la roca.  Spanish        es   \n",
       "\n",
       "       sim1  sim2  sim3      category  \n",
       "0  0.666667     0   0.0   association  \n",
       "1  0.288675     0   0.0   association  \n",
       "2  0.597614     0   0.0   association  \n",
       "3  0.094491     0   0.0  disagreement  \n",
       "4  0.612372     0   0.0      unbiased  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.base import get_categorical_col, get_numerical_col\n",
    "from src.features.encoder import pp_for_categorical_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.target_col = 'category'\n",
    "c.n_class = 3\n",
    "c.target_map = {'association': 0, 'disagreement': 1, 'unbiased': 2}\n",
    "c.target_map_rev = {0: 'association', 1: 'disagreement', 2: 'unbiased'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 's1', 's2', 'lang', 'lang_code', 'category']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_categorical_col(whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sim1', 'sim2', 'sim3']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_numerical_col(whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast \n",
    "def fix_s1s2(data):\n",
    "    new_s1 = []\n",
    "    new_s2 = []\n",
    "    for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        if row[\"s1\"].startswith(\"[\"):\n",
    "            try:\n",
    "                temp_s1 = \" \".join(ast.literal_eval(row[\"s1\"]))\n",
    "            except SyntaxError:\n",
    "                temp_s1 = row[\"s1\"][1:-1]\n",
    "        else:\n",
    "            temp_s1 = row[\"s1\"]\n",
    "\n",
    "        if row[\"s2\"].startswith(\"[\"):\n",
    "            try:\n",
    "                temp_s2 = \" \".join(ast.literal_eval(row[\"s2\"]))\n",
    "            except SyntaxError:\n",
    "                temp_s2 = row[\"s2\"][1:-1]\n",
    "        else:\n",
    "            temp_s2 = row[\"s2\"]\n",
    "\n",
    "        new_s1.append(temp_s1)\n",
    "        new_s2.append(temp_s2)\n",
    "    data[\"s1\"] = new_s1\n",
    "    data[\"s2\"] = new_s2\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc087da7e2e451caba6bdf18d1335fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/349289 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "whole = fix_s1s2(whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = whole[~whole[c.target_col].isna()].reset_index(drop=True)\n",
    "test = whole[whole[c.target_col].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelを数値に変換\n",
    "train[c.target_col] = train[c.target_col].map(c.target_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 13:54:44.407470: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-12 13:54:44.519422: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-12 13:54:44.971949: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.8/site-packages/torch/lib:/opt/conda/lib/python3.8/site-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-12 13:54:44.972005: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.8/site-packages/torch/lib:/opt/conda/lib/python3.8/site-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-12 13:54:44.972010: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, config: Config, phase: str='train'):\n",
    "        assert phase in ['train', 'valid', 'test']\n",
    "        self.config = config\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "        self.phase = phase\n",
    "        self.s1 = df['s1'].to_numpy()\n",
    "        self.s2 = df['s2'].to_numpy()\n",
    "        self.y = np.full(len(df), np.nan)\n",
    "        if self.phase in ['train', 'valid']:\n",
    "            self.y = df[config.target_col].to_numpy()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.s1.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # GET TEXT AND WORD LABELS \n",
    "        inputs1 = self.tokenizer.encode_plus(\n",
    "            self.s1[idx],\n",
    "            self.s2[idx],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.config.max_len, \n",
    "            padding='max_length',\n",
    "            truncation=True, \n",
    "            # return_attention_mask=True,\n",
    "        )\n",
    "        \n",
    "        x = {\n",
    "            'token1': torch.tensor(inputs1['input_ids'], dtype=torch.long),\n",
    "            'mask1': torch.tensor(inputs1['attention_mask'], dtype=torch.long),\n",
    "        }\n",
    "        return x, self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from torchmetrics import F1Score\n",
    "\n",
    "class CustomModel(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        # model_config = AutoConfig.from_pretrained(config.model_name)\n",
    "        # model_config.update(config.model_config_params)\n",
    "        model_config = None \n",
    "\n",
    "        self.backbone = AutoModel.from_pretrained(config.model_name, config=model_config)\n",
    "        self.ln = nn.LayerNorm(config.ndim)\n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.Linear(config.ndim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, config.n_class) \n",
    "        )\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "        self.criterion = self.get_criterion(config)\n",
    "        self.optimizer = self.get_optimizer(config)\n",
    "        self.scheduler = self.get_scheduler(config)\n",
    "        self.metric = self.get_metric(config)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        self.dropout4 = nn.Dropout(0.4)\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.backbone(x['token1'], attention_mask=x['mask1'])[\"last_hidden_state\"][:, 0, :]\n",
    "        output = self.ln(output)\n",
    "        logits1 = self.linear1(self.dropout1(output))   \n",
    "        logits2 = self.linear1(self.dropout2(output))   \n",
    "        logits3 = self.linear1(self.dropout3(output))   \n",
    "        logits4 = self.linear1(self.dropout4(output))   \n",
    "        logits5 = self.linear1(self.dropout5(output))   \n",
    "        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n",
    "        logits = torch.softmax(logits, dim=-1)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "    def _calculate_loss(self, batch, mode=\"train\"):\n",
    "        x, y = batch\n",
    "        output = self(x)\n",
    "        loss = self.criterion(output, y)\n",
    "        score = self.metric(output, y) \n",
    "\n",
    "        self.log(f'Loss/{mode}', loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        self.log(f'Score/{mode}', score, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        return loss \n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._calculate_loss(batch, mode=\"train\")\n",
    "    \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._calculate_loss(batch, mode=\"valid\")\n",
    "\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        return self(x)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return {\"optimizer\": self.optimizer, \"lr_scheduler\": self.scheduler, \"monitor\": \"Loss/valid\"}\n",
    "\n",
    "\n",
    "    def get_metric(self, config):\n",
    "        return F1Score(average='micro')\n",
    "\n",
    "\n",
    "    def get_optimizer(self, config: dict):\n",
    "\n",
    "        param_optimizer = list(self.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']  # このパラメータはweight decayしない\n",
    "        optimizer_grouped_parameters = [\n",
    "                {\n",
    "                    'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n",
    "                    'weight_decay': config.weight_decay\n",
    "                },\n",
    "                {\n",
    "                    'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n",
    "                    'weight_decay': 0.0\n",
    "                }\n",
    "            ]\n",
    "\n",
    "        optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr = config.lr,\n",
    "            betas = config.beta,\n",
    "            weight_decay = config.weight_decay,\n",
    "            )\n",
    "        return optimizer\n",
    "\n",
    "    def get_scheduler(self, config: dict):\n",
    "        num_train_optimization_steps = int(\n",
    "            config.len_loader * config.n_epochs // config.gradient_accumulation_steps\n",
    "        )\n",
    "        num_warmup_steps = int(num_train_optimization_steps * config.num_warmup_steps_rate)\n",
    "        \n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            num_training_steps=num_train_optimization_steps\n",
    "        )\n",
    "        return scheduler \n",
    "\n",
    "\n",
    "    def get_criterion(self, config: dict):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        return criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([     0,      1,      2, ..., 209567, 209571, 209572]),\n",
       "  array([     7,     11,     13, ..., 209568, 209569, 209570])),\n",
       " (array([     0,      1,      2, ..., 209569, 209570, 209572]),\n",
       "  array([     9,     17,     22, ..., 209561, 209565, 209571])),\n",
       " (array([     0,      1,      3, ..., 209570, 209571, 209572]),\n",
       "  array([     2,      5,      8, ..., 209545, 209564, 209566])),\n",
       " (array([     0,      1,      2, ..., 209570, 209571, 209572]),\n",
       "  array([     3,      4,      6, ..., 209558, 209563, 209567])),\n",
       " (array([     2,      3,      4, ..., 209569, 209570, 209571]),\n",
       "  array([     0,      1,     12, ..., 209549, 209562, 209572]))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.cv import get_kfold, get_stratifiedkfold, get_groupkfold\n",
    "cv = get_stratifiedkfold(train, c.target_col, n_splits=5)\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "def calc_score(true, pred):\n",
    "    return f1_score(true, pred.argmax(axis=1), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_device_to_dict(_dict, device):\n",
    "    for k, v in _dict.items():\n",
    "        _dict[k] = v.to(device)\n",
    "    return _dict \n",
    "    \n",
    "def to_np(input):\n",
    "    return input.detach().cpu().numpy()\n",
    "\n",
    "def worker_init_fn(worker_id):                                                          \n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "\n",
    "# def inference(model, loader, device):\n",
    "#     model.eval()\n",
    "#     model.to(device)\n",
    "#     pred = []\n",
    "#     with torch.no_grad():\n",
    "#         # https://github.com/tqdm/tqdm/issues/746\n",
    "#         for batch in tqdm(loader, total=len(loader)):\n",
    "#             with torch.autocast(device_type=device.type):\n",
    "#                 x, y = batch\n",
    "#                 x = apply_device_to_dict(x, device)\n",
    "#                 output = model(x)\n",
    "#                 pred.append(to_np(output))\n",
    "#     return np.concatenate(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipeline(train, test, cv, config, target_col):\n",
    "    for i, (idx_train, idx_valid) in enumerate(cv):\n",
    "        if i not in c.use_fold:\n",
    "            continue \n",
    "\n",
    "        wandb.init(**config.wandb_init, name=f'exp{config.version}-fold{i}', config=config)\n",
    "\n",
    "        _train = train.loc[idx_train]\n",
    "        _valid = train.loc[idx_valid]\n",
    "\n",
    "        loaders = {}\n",
    "        loaders[\"train\"] = DataLoader(CustomDataset(_train, config, phase=\"train\"), **config.loader_params['train'], worker_init_fn=worker_init_fn) \n",
    "        loaders[\"valid\"] = DataLoader(CustomDataset(_valid, config, phase=\"valid\"), **config.loader_params['valid'], worker_init_fn=worker_init_fn)\n",
    "        loaders[\"test\"] = DataLoader(CustomDataset(test, config, phase=\"test\"), **config.loader_params['test'], worker_init_fn=worker_init_fn)\n",
    "        c.len_loader = len(loaders['train'])\n",
    "\n",
    "        # callback \n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            monitor=f'Score/valid',\n",
    "            mode='max',\n",
    "            dirpath=c.output_dir,\n",
    "            filename=f'model_fold{i}_' + '{epoch}'  # pl内部のepochを読む\n",
    "            )  \n",
    "\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=f'Score/valid',\n",
    "            mode='max'\n",
    "            )\n",
    "\n",
    "        trainer = pl.Trainer(\n",
    "            logger=[WandbLogger()], \n",
    "            callbacks=[checkpoint_callback, early_stop_callback],\n",
    "            max_epochs=c.n_epochs,\n",
    "            devices='auto',\n",
    "            accelerator='auto',\n",
    "            fast_dev_run=DEBUG,\n",
    "            deterministic=True,\n",
    "            precision=16,\n",
    "            )\n",
    "\n",
    "        print('start train')\n",
    "        model = CustomModel(c)\n",
    "        trainer.fit(model, train_dataloaders=loaders['train'], val_dataloaders=loaders['valid'], ckpt_path=c.resume_checkpoint_path) # resumeする場合ここにcheckpointを渡す\n",
    "\n",
    "\n",
    "        print('create oof')\n",
    "        if not DEBUG:\n",
    "            # best_checkpoint_path = f\"{config.output_dir}/model_fold0_epoch=0.ckpt\" # \n",
    "            best_checkpoint_path = checkpoint_callback.best_model_path\n",
    "            logger.info(f'load best model {best_checkpoint_path}')\n",
    "            model = model.load_from_checkpoint(checkpoint_path=best_checkpoint_path, config=config)\n",
    "            config.best_checkpoint_path = best_checkpoint_path\n",
    "\n",
    "\n",
    "        if DEBUG:\n",
    "            idx_valid = _valid.iloc[:c.loader_params['valid']['batch_size']].index.to_list() # debug時は\n",
    "\n",
    "        preds_valid = trainer.predict(model, loaders['valid'])\n",
    "        pred_valid = to_np(torch.cat(preds_valid))\n",
    "\n",
    "        oof = pd.DataFrame(pred_valid, index=idx_valid)\n",
    "        oof.to_csv(f\"{c.output_dir}/oof_{i}.csv\", index=True) # もとの並びでconcatするときにindexが必要\n",
    "\n",
    "        # evaluate\n",
    "        print('evaluate valid data')\n",
    "        y_valid = _valid.loc[idx_valid, c.target_col]\n",
    "        score = calc_score(y_valid, pred_valid)\n",
    "        logger.info(f'fold-{i} score: {score}')\n",
    "        wandb.log({'CV': score})\n",
    "\n",
    "        # pred\n",
    "        print('inference test data')\n",
    "        preds_test = trainer.predict(model, loaders['test'])\n",
    "        pred_test = to_np(torch.cat(preds_test))\n",
    "        np.save(f\"{c.output_dir}/pred_test_{i}\", pred_test)\n",
    "\n",
    "        # wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkuto5046\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user/work/output/014/wandb/run-20221012_135447-38tdc8ss</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kuto5046/debug/runs/38tdc8ss\" target=\"_blank\">exp014-fold0</a></strong> to <a href=\"https://wandb.ai/kuto5046/debug\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:352: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /home/user/work/output/014 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type             | Params\n",
      "------------------------------------------------\n",
      "0  | backbone  | XLMRobertaModel  | 278 M \n",
      "1  | ln        | LayerNorm        | 1.5 K \n",
      "2  | linear1   | Sequential       | 197 K \n",
      "3  | dropout   | Dropout          | 0     \n",
      "4  | criterion | CrossEntropyLoss | 0     \n",
      "5  | metric    | F1Score          | 0     \n",
      "6  | dropout1  | Dropout          | 0     \n",
      "7  | dropout2  | Dropout          | 0     \n",
      "8  | dropout3  | Dropout          | 0     \n",
      "9  | dropout4  | Dropout          | 0     \n",
      "10 | dropout5  | Dropout          | 0     \n",
      "------------------------------------------------\n",
      "278 M     Trainable params\n",
      "0         Non-trainable params\n",
      "278 M     Total params\n",
      "556.486   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c2028d161a41a29bc0310c6d4351a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78c76877e5f4162be08d684984dd85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0e22f57a3b421cba0ad43bf8acdb54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f444e5fb0f3d4b84977417ba5f870a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2925d638d40b4e069b208f61568746a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa858d9ce1474bed84b0a4051c293a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82dbf294de164ffabe8b79407a793943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "[I 221012 14:54:20 671148209:50] load best model /home/user/work/output/014/model_fold0_epoch=4.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create oof\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85cca04f94614228805b68a84f36d92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 5240it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 221012 14:55:01 671148209:68] fold-0 score: 0.754527018966957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41915, 3)\n",
      "evaluate valid data\n",
      "inference test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc89c9c6fb94a739fbee425128c0044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 5240it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139716, 3)\n"
     ]
    }
   ],
   "source": [
    "train_pipeline(train, test, cv, c, c.target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(len(cv)):\n",
    "    if i not in c.use_fold:\n",
    "        continue\n",
    "    pred = np.load(f'{c.output_dir}/pred_test_{i}.npy')\n",
    "    preds.append(pred)\n",
    "pred_test = np.mean(preds, axis=0).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/opt/conda/lib/python3.8/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train[c.target_col], label='target')\n",
    "sns.distplot(pred_test, label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(f'{c.input_dir}/sample_submission.csv')\n",
    "sub[c.target_col] = pred_test\n",
    "sub.to_csv(f'{c.output_dir}/submission_exp{c.version}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
