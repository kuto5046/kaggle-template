{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sys \n",
    "import os \n",
    "import logzero \n",
    "import wandb \n",
    "import pickle \n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "sns.set()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning.utilities.seed import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN_COLAB:False, IN_KAGGLE:False, LOCAL:True\n"
     ]
    }
   ],
   "source": [
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "IN_KAGGLE = 'kaggle_web_client' in sys.modules\n",
    "LOCAL = not (IN_KAGGLE or IN_COLAB)\n",
    "print(f'IN_COLAB:{IN_COLAB}, IN_KAGGLE:{IN_KAGGLE}, LOCAL:{LOCAL}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_KAGGLE or IN_COLAB:\n",
    "    %env CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
    "    !pip install -q \\\n",
    "        pytorch-lightning==1.7.6 \\\n",
    "        logzero \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_KAGGLE:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    wandb_api_key = UserSecretsClient().get_secret(\"wandb_api\")\n",
    "    wandb.login(key=wandb_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Config():\n",
    "    # common\n",
    "    version = '014'\n",
    "    comment = 'roberta-base'\n",
    "    input_dir = '/home/user/work/input/we-are-all-alike-on-the-inside'\n",
    "    output_dir = f'/home/user/work/output/{version}' \n",
    "    seed = 42\n",
    "    debug = False\n",
    "    target_col = None \n",
    "\n",
    "    # wandb\n",
    "    wandb_init = {\n",
    "        \"project\": \"debug\",\n",
    "        \"entity\": \"kuto5046\",\n",
    "        \"group\": f\"exp{version}\",\n",
    "        \"dir\": output_dir,\n",
    "        \"tags\": [],\n",
    "        # \"resume\": True,\n",
    "        # \"mode\": \"disabled\", \n",
    "    }\n",
    "\n",
    "    # cv \n",
    "    n_splits = 5\n",
    "    use_fold = [0]  # fold1つで終える場合[0], 全てのfoldを実行する場合[0,1,2,3,4]\n",
    "\n",
    "    # dataloader\n",
    "    loader_params = {\n",
    "        \"train\": {'batch_size': 32, 'shuffle': True, 'num_workers': 4},\n",
    "        \"valid\": {'batch_size': 32, 'shuffle': False, 'num_workers': 4},\n",
    "        \"test\": {'batch_size': 32, 'shuffle': False, 'num_workers': 4} \n",
    "        }\n",
    "\n",
    "    # model\n",
    "    resume_checkpoint_path = None #f\"{output_dir}/model_fold0_epoch=6.ckpt\"  # resume用\n",
    "    # pretrained_model_path = f\"{output_dir}/model_fold0_epoch=0.ckpt\"  # 予測のみ用 \n",
    "    n_epochs = 5\n",
    "    model_name = 'xlm-roberta-base'\n",
    "    ndim = 768\n",
    "    max_len = 128\n",
    "    weight_decay = 1e-3\n",
    "    beta = (0.9, 0.98)\n",
    "    lr = 3e-5\n",
    "    num_warmup_steps_rate = 0\n",
    "    gradient_accumulation_steps = 1  # 1なら累積しない\n",
    "\n",
    "    # model_config_params = {\n",
    "    #     \"output_hidden_states\": True,\n",
    "    #     \"hidden_dropout_prob\": 0.1,\n",
    "    #     \"layer_norm_eps\": 1e-7,\n",
    "    #     \"add_pooling_layer\": True,\n",
    "    # }\n",
    "\n",
    "\n",
    "c = Config()\n",
    "DEBUG = c.debug \n",
    "if DEBUG:\n",
    "    c.wandb_init[\"mode\"] = 'disabled' \n",
    "\n",
    "\n",
    "# c = HydraConfig.get_cnf(config_path='/home/user/work/configs/', config_name='config.yaml')\n",
    "os.makedirs(c.output_dir, exist_ok=True)\n",
    "logger = logzero.setup_logger(name='main', logfile=f'{c.output_dir}/result.log', level=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "c.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "seed_everything(c.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((209573, 9), (139716, 8))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(f'{c.input_dir}/train.csv')\n",
    "test = pd.read_csv(f'{c.input_dir}/test.csv')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>lang</th>\n",
       "      <th>lang_code</th>\n",
       "      <th>sim1</th>\n",
       "      <th>sim2</th>\n",
       "      <th>sim3</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12c14e636472ca96a4d2278e0551d386</td>\n",
       "      <td>Un caméraman regarde une performance.</td>\n",
       "      <td>Un caméraman filmant une performance musicale.</td>\n",
       "      <td>French</td>\n",
       "      <td>fr</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>association</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>952d00e2403b239e9c74270bc0a95221</td>\n",
       "      <td>['Dos mujeres miran al espacio.', 'Ii charwoma...</td>\n",
       "      <td>Dos mujeres buscan en algún evento distante.</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>es</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>association</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e10fc0fe22685baa17a93d63834f2773</td>\n",
       "      <td>There is a person in the snow.</td>\n",
       "      <td>A person playing sports in the snow is crouche...</td>\n",
       "      <td>English</td>\n",
       "      <td>en</td>\n",
       "      <td>0.597614</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>association</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b137d6a58a985c4fef34a59df5dd5b82</td>\n",
       "      <td>['Der Militär steht mit seiner Gitarre.', 'Der...</td>\n",
       "      <td>Ein Mann mit weißem Tanktop und Brille steuert...</td>\n",
       "      <td>German</td>\n",
       "      <td>de</td>\n",
       "      <td>0.094491</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cfb0eb8ff2d3f5dc191db41156e4acf1</td>\n",
       "      <td>[\"el pasajero de la moto de tierra está cruzan...</td>\n",
       "      <td>un ciclista de dirt bike cruza la roca.</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>es</td>\n",
       "      <td>0.612372</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unbiased</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  12c14e636472ca96a4d2278e0551d386   \n",
       "1  952d00e2403b239e9c74270bc0a95221   \n",
       "2  e10fc0fe22685baa17a93d63834f2773   \n",
       "3  b137d6a58a985c4fef34a59df5dd5b82   \n",
       "4  cfb0eb8ff2d3f5dc191db41156e4acf1   \n",
       "\n",
       "                                                  s1  \\\n",
       "0              Un caméraman regarde une performance.   \n",
       "1  ['Dos mujeres miran al espacio.', 'Ii charwoma...   \n",
       "2                     There is a person in the snow.   \n",
       "3  ['Der Militär steht mit seiner Gitarre.', 'Der...   \n",
       "4  [\"el pasajero de la moto de tierra está cruzan...   \n",
       "\n",
       "                                                  s2     lang lang_code  \\\n",
       "0     Un caméraman filmant une performance musicale.   French        fr   \n",
       "1       Dos mujeres buscan en algún evento distante.  Spanish        es   \n",
       "2  A person playing sports in the snow is crouche...  English        en   \n",
       "3  Ein Mann mit weißem Tanktop und Brille steuert...   German        de   \n",
       "4            un ciclista de dirt bike cruza la roca.  Spanish        es   \n",
       "\n",
       "       sim1  sim2  sim3      category  \n",
       "0  0.666667     0   0.0   association  \n",
       "1  0.288675     0   0.0   association  \n",
       "2  0.597614     0   0.0   association  \n",
       "3  0.094491     0   0.0  disagreement  \n",
       "4  0.612372     0   0.0      unbiased  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.base import get_categorical_col, get_numerical_col\n",
    "from src.features.encoder import pp_for_categorical_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.target_col = 'category'\n",
    "c.n_class = 3\n",
    "c.target_map = {'association': 0, 'disagreement': 1, 'unbiased': 2}\n",
    "c.target_map_rev = {0: 'association', 1: 'disagreement', 2: 'unbiased'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 's1', 's2', 'lang', 'lang_code', 'category']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_categorical_col(whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sim1', 'sim2', 'sim3']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_numerical_col(whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast \n",
    "def fix_s1s2(data):\n",
    "    new_s1 = []\n",
    "    new_s2 = []\n",
    "    for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        if row[\"s1\"].startswith(\"[\"):\n",
    "            try:\n",
    "                temp_s1 = \" \".join(ast.literal_eval(row[\"s1\"]))\n",
    "            except SyntaxError:\n",
    "                temp_s1 = row[\"s1\"][1:-1]\n",
    "        else:\n",
    "            temp_s1 = row[\"s1\"]\n",
    "\n",
    "        if row[\"s2\"].startswith(\"[\"):\n",
    "            try:\n",
    "                temp_s2 = \" \".join(ast.literal_eval(row[\"s2\"]))\n",
    "            except SyntaxError:\n",
    "                temp_s2 = row[\"s2\"][1:-1]\n",
    "        else:\n",
    "            temp_s2 = row[\"s2\"]\n",
    "\n",
    "        new_s1.append(temp_s1)\n",
    "        new_s2.append(temp_s2)\n",
    "    data[\"s1\"] = new_s1\n",
    "    data[\"s2\"] = new_s2\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f0d0a79283472d946625c45121089f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/349289 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "whole = fix_s1s2(whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = whole[~whole[c.target_col].isna()].reset_index(drop=True)\n",
    "test = whole[whole[c.target_col].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelを数値に変換\n",
    "train[c.target_col] = train[c.target_col].map(c.target_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 00:28:15.493293: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-14 00:28:15.606799: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-14 00:28:16.058531: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.8/site-packages/torch/lib:/opt/conda/lib/python3.8/site-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-14 00:28:16.058592: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.8/site-packages/torch/lib:/opt/conda/lib/python3.8/site-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-14 00:28:16.058598: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, config: Config, phase: str='train'):\n",
    "        assert phase in ['train', 'valid', 'test']\n",
    "        self.config = config\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "        self.phase = phase\n",
    "        self.s1 = df['s1'].to_numpy()\n",
    "        self.s2 = df['s2'].to_numpy()\n",
    "        self.y = np.full(len(df), np.nan)\n",
    "        # self.y = np.full((len(df), config.n_class), np.nan)\n",
    "        if self.phase in ['train', 'valid']:\n",
    "            # self.y = pd.get_dummies(df[c.target_col]).to_numpy()  #BCE\n",
    "            self.y = df[config.target_col].to_numpy() # CrossEntropy\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.s1.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # GET TEXT AND WORD LABELS \n",
    "        inputs1 = self.tokenizer.encode_plus(\n",
    "            self.s1[idx],\n",
    "            self.s2[idx],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.config.max_len, \n",
    "            padding='max_length',\n",
    "            truncation=True, \n",
    "            # return_attention_mask=True,\n",
    "        )\n",
    "        \n",
    "        x = {\n",
    "            'token1': torch.tensor(inputs1['input_ids'], dtype=torch.long),\n",
    "            'mask1': torch.tensor(inputs1['attention_mask'], dtype=torch.long),\n",
    "        }\n",
    "        return x, torch.tensor(self.y[idx], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from torchmetrics import F1Score\n",
    "\n",
    "class CustomModel(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        # model_config = AutoConfig.from_pretrained(config.model_name)\n",
    "        # model_config.update(config.model_config_params)\n",
    "        model_config = None \n",
    "\n",
    "        self.backbone = AutoModel.from_pretrained(config.model_name, config=model_config)\n",
    "        self.ln = nn.LayerNorm(config.ndim)\n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.Linear(config.ndim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, config.n_class) \n",
    "        )\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "        self.criterion = self.get_criterion(config)\n",
    "        self.optimizer = self.get_optimizer(config)\n",
    "        self.scheduler = self.get_scheduler(config)\n",
    "        self.metric = self.get_metric(config)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        self.dropout4 = nn.Dropout(0.4)\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.backbone(x['token1'], attention_mask=x['mask1'])[\"last_hidden_state\"][:, 0, :]\n",
    "        output = self.ln(output)\n",
    "        logits1 = self.linear1(self.dropout1(output))   \n",
    "        logits2 = self.linear1(self.dropout2(output))   \n",
    "        logits3 = self.linear1(self.dropout3(output))   \n",
    "        logits4 = self.linear1(self.dropout4(output))   \n",
    "        logits5 = self.linear1(self.dropout5(output))   \n",
    "        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n",
    "        return logits\n",
    "    \n",
    "\n",
    "    def _calculate_loss(self, batch, mode=\"train\"):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        # from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "        loss = self.criterion(logits, y)\n",
    "        score = self.metric(logits, y.to(torch.long)) \n",
    "\n",
    "        self.log(f'Loss/{mode}', loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        self.log(f'Score/{mode}', score, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        return loss \n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._calculate_loss(batch, mode=\"train\")\n",
    "    \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._calculate_loss(batch, mode=\"valid\")\n",
    "\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        return self(x)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return {\"optimizer\": self.optimizer, \"lr_scheduler\": self.scheduler, \"monitor\": \"Loss/valid\"}\n",
    "\n",
    "\n",
    "    def get_metric(self, config):\n",
    "        return F1Score(average='micro')\n",
    "\n",
    "\n",
    "    def get_optimizer(self, config: dict):\n",
    "\n",
    "        param_optimizer = list(self.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']  # このパラメータはweight decayしない\n",
    "        optimizer_grouped_parameters = [\n",
    "                {\n",
    "                    'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n",
    "                    'weight_decay': config.weight_decay\n",
    "                },\n",
    "                {\n",
    "                    'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n",
    "                    'weight_decay': 0.0\n",
    "                }\n",
    "            ]\n",
    "\n",
    "        optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr = config.lr,\n",
    "            betas = config.beta,\n",
    "            weight_decay = config.weight_decay,\n",
    "            )\n",
    "        return optimizer\n",
    "\n",
    "    def get_scheduler(self, config: dict):\n",
    "        num_train_optimization_steps = int(\n",
    "            config.len_loader * config.n_epochs // config.gradient_accumulation_steps\n",
    "        )\n",
    "        num_warmup_steps = int(num_train_optimization_steps * config.num_warmup_steps_rate)\n",
    "        \n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            num_training_steps=num_train_optimization_steps\n",
    "        )\n",
    "        return scheduler \n",
    "\n",
    "\n",
    "    def get_criterion(self, config: dict):\n",
    "        # criterion = nn.BCEWithLogitsLoss() \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        return criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([     0,      1,      2, ..., 209567, 209571, 209572]),\n",
       "  array([     7,     11,     13, ..., 209568, 209569, 209570])),\n",
       " (array([     0,      1,      2, ..., 209569, 209570, 209572]),\n",
       "  array([     9,     17,     22, ..., 209561, 209565, 209571])),\n",
       " (array([     0,      1,      3, ..., 209570, 209571, 209572]),\n",
       "  array([     2,      5,      8, ..., 209545, 209564, 209566])),\n",
       " (array([     0,      1,      2, ..., 209570, 209571, 209572]),\n",
       "  array([     3,      4,      6, ..., 209558, 209563, 209567])),\n",
       " (array([     2,      3,      4, ..., 209569, 209570, 209571]),\n",
       "  array([     0,      1,     12, ..., 209549, 209562, 209572]))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.cv import get_kfold, get_stratifiedkfold, get_groupkfold\n",
    "cv = get_stratifiedkfold(train, c.target_col, n_splits=5)\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "def calc_score(true, pred):\n",
    "    return f1_score(true, pred.argmax(axis=1), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_device_to_dict(_dict, device):\n",
    "    for k, v in _dict.items():\n",
    "        _dict[k] = v.to(device)\n",
    "    return _dict \n",
    "    \n",
    "def to_np(input):\n",
    "    return input.detach().cpu().numpy()\n",
    "\n",
    "def worker_init_fn(worker_id):                                                          \n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "\n",
    "# def inference(model, loader, device):\n",
    "#     model.eval()\n",
    "#     model.to(device)\n",
    "#     pred = []\n",
    "#     with torch.no_grad():\n",
    "#         # https://github.com/tqdm/tqdm/issues/746\n",
    "#         for batch in tqdm(loader, total=len(loader)):\n",
    "#             with torch.autocast(device_type=device.type):\n",
    "#                 x, y = batch\n",
    "#                 x = apply_device_to_dict(x, device)\n",
    "#                 output = model(x)\n",
    "#                 pred.append(to_np(output))\n",
    "#     return np.concatenate(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipeline(train, test, cv, config, target_col):\n",
    "    for i, (idx_train, idx_valid) in enumerate(cv):\n",
    "        if i not in c.use_fold:\n",
    "            continue \n",
    "\n",
    "        wandb.init(**config.wandb_init, name=f'exp{config.version}-fold{i}', config=config)\n",
    "\n",
    "        _train = train.loc[idx_train]\n",
    "        _valid = train.loc[idx_valid]\n",
    "\n",
    "        loaders = {}\n",
    "        loaders[\"train\"] = DataLoader(CustomDataset(_train, config, phase=\"train\"), **config.loader_params['train'], worker_init_fn=worker_init_fn) \n",
    "        loaders[\"valid\"] = DataLoader(CustomDataset(_valid, config, phase=\"valid\"), **config.loader_params['valid'], worker_init_fn=worker_init_fn)\n",
    "        loaders[\"test\"] = DataLoader(CustomDataset(test, config, phase=\"test\"), **config.loader_params['test'], worker_init_fn=worker_init_fn)\n",
    "        c.len_loader = len(loaders['train'])\n",
    "\n",
    "        # callback \n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            monitor=f'Score/valid',\n",
    "            mode='max',\n",
    "            dirpath=c.output_dir,\n",
    "            filename=f'model_fold{i}_' + '{epoch}'  # pl内部のepochを読む\n",
    "            )  \n",
    "\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=f'Score/valid',\n",
    "            mode='max'\n",
    "            )\n",
    "\n",
    "        trainer = pl.Trainer(\n",
    "            logger=[WandbLogger()], \n",
    "            callbacks=[checkpoint_callback, early_stop_callback],\n",
    "            max_epochs=c.n_epochs,\n",
    "            devices='auto',\n",
    "            accelerator='auto',\n",
    "            fast_dev_run=DEBUG,\n",
    "            deterministic=True,\n",
    "            precision=16,\n",
    "            )\n",
    "\n",
    "        print('start train')\n",
    "        model = CustomModel(c)\n",
    "        trainer.fit(model, train_dataloaders=loaders['train'], val_dataloaders=loaders['valid'], ckpt_path=c.resume_checkpoint_path) # resumeする場合ここにcheckpointを渡す\n",
    "\n",
    "\n",
    "        print('create oof')\n",
    "        if not DEBUG:\n",
    "            # best_checkpoint_path = f\"{config.output_dir}/model_fold0_epoch=0.ckpt\" # \n",
    "            best_checkpoint_path = checkpoint_callback.best_model_path\n",
    "            logger.info(f'load best model {best_checkpoint_path}')\n",
    "            model = model.load_from_checkpoint(checkpoint_path=best_checkpoint_path, config=config)\n",
    "            config.best_checkpoint_path = best_checkpoint_path\n",
    "\n",
    "\n",
    "        if DEBUG:\n",
    "            idx_valid = _valid.iloc[:c.loader_params['valid']['batch_size']].index.to_list() # debug時は\n",
    "\n",
    "        preds_valid = trainer.predict(model, loaders['valid'])\n",
    "        pred_valid = to_np(torch.cat(preds_valid))\n",
    "\n",
    "        oof = pd.DataFrame(pred_valid, index=idx_valid)\n",
    "        oof.to_csv(f\"{c.output_dir}/oof_{i}.csv\", index=True) # もとの並びでconcatするときにindexが必要\n",
    "\n",
    "        # evaluate\n",
    "        print('evaluate valid data')\n",
    "        y_valid = _valid.loc[idx_valid, c.target_col]\n",
    "        score = calc_score(y_valid, pred_valid)\n",
    "        logger.info(f'fold-{i} score: {score}')\n",
    "        wandb.log({'CV': score})\n",
    "\n",
    "        # pred\n",
    "        print('inference test data')\n",
    "        preds_test = trainer.predict(model, loaders['test'])\n",
    "        pred_test = to_np(torch.cat(preds_test))\n",
    "        np.save(f\"{c.output_dir}/pred_test_{i}\", pred_test)\n",
    "\n",
    "        # wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkuto5046\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user/work/output/015/wandb/run-20221014_002818-28jp3342</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kuto5046/debug/runs/28jp3342\" target=\"_blank\">exp015-fold0</a></strong> to <a href=\"https://wandb.ai/kuto5046/debug\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:352: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /home/user/work/output/015 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type              | Params\n",
      "-------------------------------------------------\n",
      "0  | backbone  | XLMRobertaModel   | 278 M \n",
      "1  | ln        | LayerNorm         | 1.5 K \n",
      "2  | linear1   | Sequential        | 197 K \n",
      "3  | dropout   | Dropout           | 0     \n",
      "4  | criterion | BCEWithLogitsLoss | 0     \n",
      "5  | metric    | F1Score           | 0     \n",
      "6  | dropout1  | Dropout           | 0     \n",
      "7  | dropout2  | Dropout           | 0     \n",
      "8  | dropout3  | Dropout           | 0     \n",
      "9  | dropout4  | Dropout           | 0     \n",
      "10 | dropout5  | Dropout           | 0     \n",
      "-------------------------------------------------\n",
      "278 M     Trainable params\n",
      "0         Non-trainable params\n",
      "278 M     Total params\n",
      "556.486   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17a40db869b445b94179ec899fbad4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554e8f0e47ef470a89f213e8739c0529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54574ad94e241f6be593968e50be7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94654b85a6747d59b24ba54e6f744fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f6bb532d6645a1814558b7b03851dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e94bcfd81414c7fbe2141e70c3c626e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f41d0b3719c4211bc7dce4630b0cb96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ee92bfdd1042f68f7951739d674b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 221014 01:39:04 728389278:50] load best model /home/user/work/output/015/model_fold0_epoch=2.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create oof\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22954055ce284d71bbb73c6cf2f417a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 5240it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 221014 01:39:45 728389278:68] fold-0 score: 0.7049982106644399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate valid data\n",
      "inference test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ff44a3beb1402dbaad5bc9c48f88e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 5240it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_pipeline(train, test, cv, c, c.target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(len(cv)):\n",
    "    if i not in c.use_fold:\n",
    "        continue\n",
    "    pred = np.load(f'{c.output_dir}/pred_test_{i}.npy')\n",
    "    preds.append(pred)\n",
    "pred_test = np.mean(preds, axis=0).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/opt/conda/lib/python3.8/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train[c.target_col], label='target')\n",
    "sns.distplot(pred_test, label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(f'{c.input_dir}/sample_submission.csv')\n",
    "sub[c.target_col] = pred_test\n",
    "sub.to_csv(f'{c.output_dir}/submission_exp{c.version}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
