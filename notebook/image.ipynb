{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sys \n",
    "import os \n",
    "import logzero \n",
    "import wandb \n",
    "import pickle \n",
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from typing import List\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from pathlib import Path \n",
    "import timm \n",
    "from glob import glob\n",
    "import PIL \n",
    "from torchmetrics import F1Score, Accuracy\n",
    "# import albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# url = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\"\n",
    "# torchvision.datasets.utils.download_and_extract_archive(url, '../input/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import noglobal, pickle_load, pickle_save, HydraConfig\n",
    "\n",
    "class Config():\n",
    "    # common\n",
    "    version = '001'\n",
    "    comment = 'test'\n",
    "    input_dir = '/home/user/work/input/hymenoptera_data'\n",
    "    output_dir = f'/home/user/work/output/{version}' \n",
    "    seed = 42\n",
    "    debug = False\n",
    "\n",
    "    # wandb\n",
    "    wandb_init = {\n",
    "        \"project\": \"debug\",\n",
    "        \"entity\": \"kuto5046\",\n",
    "        \"group\": f\"exp{version}\",\n",
    "        \"dir\": output_dir,\n",
    "        \"tags\": [],\n",
    "        # \"mode\": \"disabled\", \n",
    "    }\n",
    "\n",
    "    # train\n",
    "    n_class = 2\n",
    "    n_epochs = 20\n",
    "    resume_checkpoint_path = None\n",
    "    \n",
    "    # cv\n",
    "    n_splits = 5\n",
    "    use_fold = [0]  # fold1つで終える場合[0], 全てのfoldを実行する場合[0,1,2,3,4]\n",
    "\n",
    "    # dataloader\n",
    "    loader_params = {\n",
    "        \"train\": {'batch_size': 32, 'shuffle': True, 'num_workers': 4},\n",
    "        \"valid\": {'batch_size': 32, 'shuffle': False, 'num_workers': 4},\n",
    "        \"test\": {'batch_size': 32, 'shuffle': False, 'num_workers': 4} \n",
    "        }\n",
    "    \n",
    "    # model \n",
    "    model_name = 'resnet18' # タスクや使うモデルに応じて変更\n",
    "    hidden_dim = 256\n",
    "    out_dim = n_class\n",
    "    \n",
    "\n",
    "c = Config()\n",
    "DEBUG = c.debug \n",
    "if DEBUG:\n",
    "    c.wandb_init[\"mode\"] = 'disabled' \n",
    "# c = HydraConfig.get_cnf(config_path='/home/user/work/configs/', config_name='config.yaml')\n",
    "os.makedirs(c.output_dir, exist_ok=True)\n",
    "logger = logzero.setup_logger(name='main', logfile=f'{c.output_dir}/result.log', level=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMAGE_DATADIR = Path(c.input_dir) / 'train'\n",
    "TEST_IMAGE_DATADIR = Path(c.input_dir) / 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_files = []\n",
    "for file in glob(str(TRAIN_IMAGE_DATADIR/\"*\"/\"*\")): \n",
    "    image = np.array(PIL.Image.open(file))\n",
    "    if image.ndim == 3:\n",
    "        train_labels.append(file.split('/')[-2])\n",
    "        train_files.append(file)\n",
    "train_files = np.array(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testではないけどダミーで作成(本来はラベルない)\n",
    "test_labels = []\n",
    "test_files = []\n",
    "for file in glob(str(TEST_IMAGE_DATADIR/\"*\"/\"*\")): \n",
    "    image = np.array(PIL.Image.open(file))\n",
    "    if image.ndim == 3:\n",
    "        test_labels.append(file.split('/')[-2])\n",
    "        test_files.append(file)\n",
    "test_files = np.array(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_dict(input_dict):\n",
    "    return {v: k for k, v in input_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2num_mapping = {'ants': 0, 'bees': 1}\n",
    "num2class_mapping = reverse_dict(class2num_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.Series(train_labels).map(class2num_mapping).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
       " 'num_classes': 1000,\n",
       " 'input_size': (3, 224, 224),\n",
       " 'pool_size': (7, 7),\n",
       " 'crop_pct': 0.875,\n",
       " 'interpolation': 'bilinear',\n",
       " 'mean': (0.485, 0.456, 0.406),\n",
       " 'std': (0.229, 0.224, 0.225),\n",
       " 'first_conv': 'conv1',\n",
       " 'classifier': 'fc',\n",
       " 'architecture': 'resnet18'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.create_model('resnet18').default_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\n",
    "\n",
    "fold = StratifiedKFold(n_splits=c.n_splits, shuffle=True, random_state=c.seed)\n",
    "cv = list(fold.split(X=train_files, y=train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, files, labels=None, phase: str='train'):\n",
    "        assert phase in ['train', 'valid', 'test']\n",
    "        self.phase = phase\n",
    "        self.files = files \n",
    "        self.labels = labels\n",
    "        self.transformer = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.files[idx]\n",
    "        image = np.array(PIL.Image.open(path))\n",
    "        image = self.transformer(image)\n",
    "        if self.labels is None:\n",
    "            return image, -1\n",
    "        else:\n",
    "            target = self.labels[idx]\n",
    "            return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2710104495.py, line 88)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [13]\u001b[0;36m\u001b[0m\n\u001b[0;31m    metric =\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def to_np(input):\n",
    "    return input.detach().cpu().numpy()\n",
    "\n",
    "def worker_init_fn(worker_id):                                                          \n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "\n",
    "\n",
    "class CustomModel(pl.LightningModule):\n",
    "    \"\"\" \n",
    "    使えるmodelは以下のような感じで調べられる\n",
    "    timm.list_models('*swin*', pretrained=True)\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=True, num_classes=0)  # num_classes=0でbackboneとして使える引数でpoolingも除外可能\n",
    "        self.in_features = self.backbone.num_features\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.in_features, hidden_dim),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "        self.num_classes = out_dim \n",
    "\n",
    "        self.metric = self.get_metric()\n",
    "        self.criterion = self.get_criterion()\n",
    "        self.optimizer = self.get_optimizer()\n",
    "        self.scheduler = self.get_scheduler()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.backbone(x)\n",
    "        y = self.head(h)\n",
    "        return y\n",
    "        \n",
    "\n",
    "    def _calculate_loss(self, batch, mode=\"train\"):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)  # self(x)でもok\n",
    "        # from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "        loss = self.criterion(logits, y)\n",
    "        score = self.metric(logits, y.to(torch.long)) \n",
    "\n",
    "        self.log(f'Loss/{mode}', loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        self.log(f'Score/{mode}', score, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        return loss \n",
    "\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._calculate_loss(batch, mode=\"train\")\n",
    "    \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._calculate_loss(batch, mode=\"valid\")\n",
    "\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        return self.forward(x)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return {\"optimizer\": self.optimizer, \"lr_scheduler\": self.scheduler, \"monitor\": \"Loss/val\"}\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        params = [param for name, param in list(self.named_parameters())]\n",
    "        optimizer = torch.optim.AdamW(params, lr=0.01)\n",
    "        # optimizer = torch.optim.Adam(self.named_parameters(), lr=0.01)\n",
    "        return optimizer\n",
    "    \n",
    "\n",
    "    def get_scheduler(self):\n",
    "        # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, factor=0.9, patience=3)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=10)\n",
    "        return scheduler\n",
    "\n",
    "\n",
    "    def get_criterion(self):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        # criterion = nn.BCEWithLogitsLoss()\n",
    "        return criterion\n",
    "    \n",
    "\n",
    "    def get_metric(self):\n",
    "        # metric = F1Score(self.num_classes, average='micro')\n",
    "        metric = Accuracy(num_classes=self.num_classes)\n",
    "        return metric "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "def calc_score(true, pred):\n",
    "    return f1_score(true, pred.argmax(axis=1), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipeline(train_files, test_files, labels, cv, config):\n",
    "    for i, (idx_train, idx_valid) in enumerate(cv):\n",
    "        if i not in c.use_fold:\n",
    "            continue \n",
    "\n",
    "        wandb.init(**config.wandb_init, name=f'exp{config.version}-fold{i}', config=config)\n",
    "\n",
    "        _train_files = train_files[idx_train]\n",
    "        _valid_files = train_files[idx_valid]\n",
    "        train_labels = labels[idx_train]\n",
    "        valid_labels = labels[idx_valid]\n",
    "\n",
    "        loaders = {}\n",
    "        loaders[\"train\"] = DataLoader(CustomDataset(_train_files, train_labels, phase=\"train\"), **config.loader_params['train'], worker_init_fn=worker_init_fn) \n",
    "        loaders[\"valid\"] = DataLoader(CustomDataset(_valid_files, valid_labels, phase=\"valid\"), **config.loader_params['valid'], worker_init_fn=worker_init_fn)\n",
    "        loaders[\"test\"] = DataLoader(CustomDataset(test_files, phase=\"test\"), **config.loader_params['test'], worker_init_fn=worker_init_fn)\n",
    "        c.len_loader = len(loaders['train'])\n",
    "\n",
    "        # callback \n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            monitor=f'Score/valid',\n",
    "            mode='max',\n",
    "            dirpath=c.output_dir,\n",
    "            filename=f'model_fold{i}_' + '{epoch}'  # pl内部のepochを読む\n",
    "            )  \n",
    "\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor=f'Loss/valid',\n",
    "            mode='min'\n",
    "            )\n",
    "\n",
    "        trainer = pl.Trainer(\n",
    "            logger=[WandbLogger()], \n",
    "            callbacks=[checkpoint_callback, early_stop_callback],\n",
    "            max_epochs=c.n_epochs,\n",
    "            devices='auto',\n",
    "            accelerator='auto',\n",
    "            fast_dev_run=DEBUG,\n",
    "            deterministic=True,\n",
    "            precision=16,\n",
    "            )\n",
    "\n",
    "        print('start train')\n",
    "        model = CustomModel(config.model_name, config.hidden_dim, config.out_dim)\n",
    "        trainer.fit(model, train_dataloaders=loaders['train'], val_dataloaders=loaders['valid'], ckpt_path=c.resume_checkpoint_path) # resumeする場合ここにcheckpointを渡す\n",
    "\n",
    "\n",
    "        print('create oof')\n",
    "        if not DEBUG:\n",
    "            # best_checkpoint_path = f\"{config.output_dir}/model_fold0_epoch=0.ckpt\" # \n",
    "            best_checkpoint_path = checkpoint_callback.best_model_path\n",
    "            logger.info(f'load best model {best_checkpoint_path}')\n",
    "            model = model.load_from_checkpoint(checkpoint_path=best_checkpoint_path, model_name=config.model_name, hidden_dim=config.hidden_dim, out_dim=config.out_dim)  # 引数をもとのmodelと合わせる\n",
    "            config.best_checkpoint_path = best_checkpoint_path\n",
    "\n",
    "\n",
    "        # if DEBUG:\n",
    "            # idx_valid = _valid.iloc[:c.loader_params['valid']['batch_size']].index.to_list() # debug時は\n",
    "\n",
    "        preds_valid = trainer.predict(model, loaders['valid'])\n",
    "        pred_valid = to_np(torch.cat(preds_valid))\n",
    "\n",
    "        oof = pd.DataFrame(pred_valid, index=idx_valid)\n",
    "        oof.to_csv(f\"{c.output_dir}/oof_{i}.csv\", index=True) # もとの並びでconcatするときにindexが必要\n",
    "\n",
    "        # evaluate\n",
    "        print('evaluate valid data')\n",
    "        score = calc_score(valid_labels, pred_valid)\n",
    "        logger.info(f'fold-{i} score: {score}')\n",
    "        wandb.log({'CV': score})\n",
    "\n",
    "        # pred\n",
    "        print('inference test data')\n",
    "        preds_test = trainer.predict(model, loaders['test'])\n",
    "        pred_test = to_np(torch.cat(preds_test))\n",
    "        np.save(f\"{c.output_dir}/pred_test_{i}\", pred_test)\n",
    "\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkuto5046\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user/work/output/001/wandb/run-20221023_124307-9o0fuyqq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kuto5046/debug/runs/9o0fuyqq\" target=\"_blank\">exp001-fold0</a></strong> to <a href=\"https://wandb.ai/kuto5046/debug\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:352: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /home/user/work/output/001 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | backbone  | ResNet           | 11.2 M\n",
      "1 | head      | Sequential       | 131 K \n",
      "2 | metric    | F1Score          | 0     \n",
      "3 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "11.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.3 M    Total params\n",
      "22.617    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea08613176424948a2b61b8e3dd1c9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1892: PossibleUserWarning: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54769d20820b4df4b7f8b413efb4b06d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f054dff8a59146fd8270c673d9e6c520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 221023 12:43:17 22427248:52] load best model /home/user/work/output/001/model_fold0_epoch=0-v7.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create oof\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4519034fbc0243c1875a1adbd403b1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 7it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 221023 12:43:18 22427248:69] fold-0 score: 0.4897959183673469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate valid data\n",
      "inference test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93483f2475a94313804e300c3926ab56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 7it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c920f4715cf94e72a504528384754ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>CV</td><td>▁</td></tr><tr><td>Loss/train</td><td>▁</td></tr><tr><td>Score/train</td><td>▁</td></tr><tr><td>Score/valid</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>CV</td><td>0.4898</td></tr><tr><td>Loss/train</td><td>4.31446</td></tr><tr><td>Loss/valid</td><td>inf</td></tr><tr><td>Score/train</td><td>0.50769</td></tr><tr><td>Score/valid</td><td>0.4898</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>trainer/global_step</td><td>6</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">exp001-fold0</strong>: <a href=\"https://wandb.ai/kuto5046/debug/runs/9o0fuyqq\" target=\"_blank\">https://wandb.ai/kuto5046/debug/runs/9o0fuyqq</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/home/user/work/output/001/wandb/run-20221023_124307-9o0fuyqq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_pipeline(train_files, test_files, train_labels, cv, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(len(cv)):\n",
    "    if i not in c.use_fold:\n",
    "        continue\n",
    "    pred = np.load(f'{c.output_dir}/pred_test_{i}.npy')\n",
    "    preds.append(pred)\n",
    "pred_test = np.mean(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-14784.,   9744.],\n",
       "       [-30400.,  20304.],\n",
       "       [-46464.,  30864.],\n",
       "       [-41056.,  27440.],\n",
       "       [-45472.,  30304.],\n",
       "       [-32800.,  21984.],\n",
       "       [-45792.,  30288.],\n",
       "       [-41856.,  27952.],\n",
       "       [-30688.,  20400.],\n",
       "       [-19200.,  12864.],\n",
       "       [-13520.,   8720.],\n",
       "       [-51936.,  34720.],\n",
       "       [-15912.,  10680.],\n",
       "       [-36928.,  24688.],\n",
       "       [-11576.,   7624.],\n",
       "       [-41280.,  27616.],\n",
       "       [-45312.,  30416.],\n",
       "       [-16240.,  10680.],\n",
       "       [-47584.,  31632.],\n",
       "       [-35840.,  24000.],\n",
       "       [-43520.,  28976.],\n",
       "       [-22624.,  15104.],\n",
       "       [-15096.,   9848.],\n",
       "       [-29728.,  19888.],\n",
       "       [-22992.,  15208.],\n",
       "       [-33344.,  22384.],\n",
       "       [-44416.,  29728.],\n",
       "       [-45920.,  30640.],\n",
       "       [-35744.,  23984.],\n",
       "       [-35808.,  24064.],\n",
       "       [-36864.,  24512.],\n",
       "       [-39328.,  26208.],\n",
       "       [-43008.,  28784.],\n",
       "       [-17904.,  11856.],\n",
       "       [-16032.,  10712.],\n",
       "       [-41824.,  27808.],\n",
       "       [-17472.,  11744.],\n",
       "       [-36160.,  23936.],\n",
       "       [-43264.,  28816.],\n",
       "       [-11664.,   7624.],\n",
       "       [-20064.,  13416.],\n",
       "       [-48064.,  31952.],\n",
       "       [ -7424.,   4996.],\n",
       "       [-31664.,  21248.],\n",
       "       [ -6944.,   4616.],\n",
       "       [-49696.,  33024.],\n",
       "       [-34016.,  22736.],\n",
       "       [-49696.,  33120.],\n",
       "       [-14112.,   9448.],\n",
       "       [-43680.,  29136.],\n",
       "       [-41568.,  27552.],\n",
       "       [-16176.,  10256.],\n",
       "       [-24032.,  15976.],\n",
       "       [-25088.,  16784.],\n",
       "       [-10528.,   6984.],\n",
       "       [-13160.,   8840.],\n",
       "       [-40544.,  26992.],\n",
       "       [ -8880.,   5920.],\n",
       "       [-27040.,  18160.],\n",
       "       [-20672.,  13656.],\n",
       "       [-46784.,  31280.],\n",
       "       [-53088.,  35360.],\n",
       "       [-51648.,  34368.],\n",
       "       [-35296.,  23632.],\n",
       "       [-12728.,   8312.],\n",
       "       [ -6604.,   4296.],\n",
       "       [-17392.,  11520.],\n",
       "       [-29024.,  19408.],\n",
       "       [-10640.,   6824.],\n",
       "       [-26032.,  17376.],\n",
       "       [-30016.,  20000.],\n",
       "       [-21712.,  14504.],\n",
       "       [-40000.,  26656.],\n",
       "       [-31360.,  20944.],\n",
       "       [-16144.,  10744.],\n",
       "       [-21216.,  14008.],\n",
       "       [-40928.,  27248.],\n",
       "       [-15048.,   9952.],\n",
       "       [-41792.,  27920.],\n",
       "       [-37440.,  24912.],\n",
       "       [-28128.,  18720.],\n",
       "       [-35520.,  23600.],\n",
       "       [-44384.,  29760.],\n",
       "       [-16312.,  10864.],\n",
       "       [-22928.,  15352.],\n",
       "       [-36576.,  24400.],\n",
       "       [-28560.,  19088.],\n",
       "       [-40608.,  27200.],\n",
       "       [-49792.,  33024.],\n",
       "       [-28960.,  19360.],\n",
       "       [-30112.,  20192.],\n",
       "       [-45760.,  30400.],\n",
       "       [ -9072.,   5908.],\n",
       "       [-16024.,  10680.],\n",
       "       [-30448.,  20208.],\n",
       "       [-39520.,  26224.],\n",
       "       [-11208.,   7048.],\n",
       "       [-32144.,  21536.],\n",
       "       [-23584.,  15744.],\n",
       "       [-15248.,  10224.],\n",
       "       [-12880.,   8368.],\n",
       "       [ -8552.,   5396.],\n",
       "       [-33792.,  22400.],\n",
       "       [-49088.,  32512.],\n",
       "       [-39552.,  26416.],\n",
       "       [-36000.,  23920.],\n",
       "       [-13808.,   8888.],\n",
       "       [-19984.,  13376.],\n",
       "       [-33152.,  22240.],\n",
       "       [ -9528.,   6100.],\n",
       "       [-42816.,  28512.],\n",
       "       [-13544.,   9104.],\n",
       "       [-44096.,  29456.],\n",
       "       [-28320.,  18960.],\n",
       "       [-37056.,  24816.],\n",
       "       [-13896.,   9232.],\n",
       "       [-53760.,  35808.],\n",
       "       [-43136.,  28864.],\n",
       "       [-11400.,   7392.],\n",
       "       [-47712.,  31600.],\n",
       "       [-25312.,  16912.],\n",
       "       [-45440.,  30032.],\n",
       "       [-43424.,  28832.],\n",
       "       [-21376.,  14152.],\n",
       "       [-31600.,  20816.],\n",
       "       [-18000.,  12024.],\n",
       "       [-45056.,  30000.],\n",
       "       [-24688.,  16384.],\n",
       "       [-40032.,  26576.],\n",
       "       [-45472.,  30160.],\n",
       "       [-29232.,  19392.],\n",
       "       [-40960.,  27312.],\n",
       "       [-48576.,  32368.],\n",
       "       [-43712.,  29184.],\n",
       "       [-36960.,  24688.],\n",
       "       [-59424.,  39200.],\n",
       "       [-20704.,  13680.],\n",
       "       [-47232.,  31424.],\n",
       "       [-19632.,  13208.],\n",
       "       [-22128.,  14840.],\n",
       "       [-17872.,  11632.],\n",
       "       [-20768.,  13728.],\n",
       "       [-15344.,  10128.],\n",
       "       [-13336.,   8528.],\n",
       "       [-15264.,   9912.],\n",
       "       [-11128.,   7432.],\n",
       "       [-16784.,  11112.],\n",
       "       [-30688.,  20528.],\n",
       "       [   -inf,  44480.],\n",
       "       [-35360.,  23584.],\n",
       "       [-22080.,  14872.],\n",
       "       [-16016.,  10672.],\n",
       "       [-16864.,  11024.]], dtype=float16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(f'{c.input_dir}/sample_submission.csv')\n",
    "sub['label'] = pred_test\n",
    "sub.to_csv(f'{c.output_dir}/submission_exp{c.version}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
